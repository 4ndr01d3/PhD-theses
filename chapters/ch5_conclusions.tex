\begin{savequote}[75mm] 
As palavras são apenas pedras postas a atravessar a corrente de um rio, se estão ali é para que possamos chegar à outra margem, a outra margem é que importa.
\qauthor{José Saramago, A Caverna} 
\end{savequote}

\chapter{Conclusions}

\newthought{Bioinformatics offers numerous alternatives to elucidate biological knowledge in cases where experimental analysis is limited}. In some cases the restrictions are imposed by the elevated prices of using a specific technology, in others the technology simply does not exist, or when it does, the outcome needs to be extensively processed before being able to reach any conclusions. 

In order to extract information from the collected data, mathematical models are executed in computational machines, from which aggregated values, statistical outliers, and clusters of information form the clues of a puzzle that require deep biological knowledge to be solved.

Bioinformatics has been used to predict the features of biological entities, to identify patterns in multiple samples, and to simulate biological behaviour. All of which required data to be collected from multiple experiments both \emph{in-vivo} and \emph{in-vitro}, and even from \emph{in-silico} data where the values have been predicted in previous bioinformatics experiments.

We consider that the key to understand biological systems lies in the integration of relevant sources. For example,  the analysis of a particular protein can identify an enzymatic behaviour, its subtracts and products, however the impact of such a process can only understood by considering where the reaction is happening, which other proteins are present, what the concentration values of the different molecules in the environment are, are there any reactions to be triggered when the product concentration increases, etc.

The previous example is taken from a field known as system biology, which by nature has a holistic approach to studying biological processes. However similar examples can be found in other sub fields, where their focus is on a particular biological product: genes are only expressed under certain conditions, and there are molecules that can inhibit the process.

Researchers focused on these processes require the correct infrastructure to support multiple sources and integrate the raw data from them in order to find explanations to important biological questions. The chapters in this document present some contributions to the methods and tools used to explore and interpret biological data from several sources, which have been classified between integration and visualisation of information. This classification however has been used here with the only purpose of organising the text. We consider that both integration and visualisation are fully interconnected fields and the line dividing them is fuzzy or non existent.

\vspace{5mm}

In Chapter \ref{ch:introduction} we presented the current landscape of tools and methods that offer solutions to integrate and visualise biological data. There we explored different fields, such as genomics and proteomics, using different technologies, for example data warehousing or web services. The common denominator of the presented projects is their inclusive nature: communities supporting the selected standards, building tools that facilitate their adoption. 

Human resources are the most important factor in the success of these projects: a strong community backing up a project influences its growth. Such growth can be sometimes expressed as the number of data submissions, or the creation of new components or protocol extensions, or contributions to the development of open source projects.

We noticed that some of the most successful projects use a strategy where, by the means of scientific publications, both the individuals and the projects  benefit. When a project can be extended, and each extension can be considered a research outcome, the individuals involved are more likely to contribute to the project because their efforts can be recognised in a research article, which at present is the best way of building a scientific reputation. The project simultaneously gets more exposure because of the article, and more importantly, it has been improved by the individual's contribution.

\vspace{5mm}

The Distributed Annotation System (DAS) is a community project that grew for several years using the model above, and its methods to share, integrate and visualise biological data have been used and extended by many researchers. In chapter \ref{section:integration} we introduced our contributions to the project, from protocol extensions to software tools that both integrate and visualise the resources provided by the federated data sources.

We collaborated in the design and development of MyDAS(\url{https://code.google.com/p/mydas/}), a DAS server that facilitates the publication of biological data under the DAS protocol. MyDAS has been used in small projects in order to publish their data in a format that facilitates their visualisation in context with well known resources. Bigger data providers have also benefited from MyDAS. UniProt, for example, share their data in different formats, one of which is DAS, and the tool they used to achieve this functionality is MyDAS.

We collaborated in the development of MyDAS in several ways: an upgrade of the whole system was implemented in order to support the most recent version of the DAS protocol (1.6E). This version of DAS includes support for extensions to the protocol, and we have implemented several of these extensions in the core of MyDAS to facilitate their adoption. Some of these extensions were designed, proposed, accepted and implemented as part of this PhD. 

The DAS writeback (\url{https://code.google.com/p/writeback/}) provides a method for users of the DAS protocol to include new annotations or edit existing ones in such a way that their contribution can be immediately accessed by other users, but without compromising the original data shared by the providers. An implementation of this extension that supports the community annotations of proteins was installed at the EBI servers, and the DAS client DASty was extended in order to support the creation and display of writeback annotations in context with existing DAS annotations. This extension was available in the DASty installation at the EBI for over a year during 2011 and 2012. Unfortunately its adoption was very limited and therefore the extension was disabled.

We also collaborated in the design of the newest version of DASty. In DASty3, the developer will find a more modular architecture that supports the inclusion of plugins and allows the communication between them via an events model. DASty3 is the current version of the well known DAS client and can be accessed at \url{www.ebi.ac.uk/dasty}.

Another extension we proposed for DAS and implemented on MyDAS was called advanced search, which extends the DAS  protocol to support more generic queries based on the Lucene query language. This extension was then used when we implemented a tool that helps to find a microarray chip that includes probes for proteins of interest (\url{http://biosual.cbio.uct.ac.za/probes-search/}).

Throughout the duration of this PhD, we have witnessed different stages of DAS as a community project: it started as a promising technology that several well-known institutions decided to include as a way of publishing their data, which attracted many developers including ourselves, and we subsequently created various new tools and extensions to the protocol. Unfortunately, the interest in this technology has diminished, and its use has decreased to the point where large bioinformatics groups, who were supporting it at the onset, are now deprecating all DAS related services.

Although we are aware of exciting new technologies that provide similar functionalities to that of DAS, such as UniProt's REST services and libraries for web components that facilitate the creation of web resources, we argue that the main benefit of DAS, i.e. the standardisation of a publishing method, is not yet provided by any of the alternative developments.  Therefore, we regret the decision taken by some entities to no longer support the DAS community.

\vspace{5mm}

One of the new development efforts to provide a standard view of biological data, is BioJS, a collaborative project where we have contributed to their design and planning, and also in the development of individual components.  The outcome of each collaborative effort is described in the first part of Chapter \ref{section:visualisation}. Collectively, BioJS provides a library of components that represent different types of biological data on the web. 

One of the ways in which BioJS hopes to attract the community, is to simplify the different developmental stages of a web component: develop, discover, test, use, combine, customise, extend and maintain. For each of these stages there are recommended protocols and/or technologies that serve as guidelines for the developer, making the BioJS ecosystem a productive space for component creators, users and data providers.

We have developed BioJS components to represent several biological entities, such as chromosomes, proteins and their interaction networks. The representation of PPI networks was an attractive option, since these networks were, and still are, used in several research projects within our department (Chapter \ref{section:use_cases}) We decided to start a cooperative effort with our peers, where we received first hand information about requirements, data formats and usability needs, and they obtained a tool that had been tailored to their needs.

The resulting tool is PINV, which was described in detail in the section \ref{section:pinv}. PINV is a web-based application designed to explore and visualise protein-protein interactions. It currently supports four modes of presentation: a node-link representation with force-directed layout, a circlular layout, a heat map viewer, and a table format for exploring the raw data. 

As a web-based tool, PINV is an invaluable resource for collaborative functionalities. For example, the real-time visualisation can be saved by copying, and storing the link to that page. Any individual with that link can obtain an exact replica of that particular visualisation using any modern web browser, and continue the analysis and exploration on a separate instance of PINV. It is also possible to generate the code for embedding the saved view into another web page, and for instance, use the code to explain concepts dynamically  in either blogs or websites. We hope that these functionalities empower international collaborations using PPI networks.

Even though the work in this document has mainly focussed on using visualisation for integrating and exploring data, there are various applications of the existing visualisation methods. For instance, our efforts in DASty3 were about using the infrastructure offered by DAS in order to provide a tool where researchers can have an integrative view of all the annotations. In contrast, the main purpose of PINV is to facilitate the exploration of datasets that are too large to be represented in a single view, and therefore aggregated representations and filtered views have been developed with the toolset.

The development of software tools is an ongoing process, there are always new features to include, existing ones to improve, old ones to replace and obsolete ones to remove. The PINV roadmap still contains many avenues for exploration, and, in the subsequent section, we will describe several features that will further improve the tool and which we aim to implement in future research.

The fist relates to the data loading/upload process. We believe that PINV should be able to not only import data from all the standard file formats used in PPI network research, such as the ones in PSICQUIC, but it should also support the file formats of popular applications designed to visualise PPI networks, for example Cytoscape. Furthermore, to increase the breadth of allowed data formats, an option should exist for a user to import the networks defined in public resources (e.g. STRING and I2D). Similarly, we aim for PINV to provide a source of annotation for proteins, such as querying the UniProt database to obtain associated annotations. User may further require that features related to the network topology also are calculated by the PINV server when a new network is loaded. In other words, future development of PINV will bring additional support to the uploading process.

The modular architecture of PINV hasn't been used as much as it could, and currently only the PINV creators know of its existence. This is mainly due to incomplete documentation that would allow other developers to create their own PINV widgets. Currently, no protocol for the inclusion of new widgets in the application exists. However, in future we hope to provide the full API of PINV, which will enable developers to create and include their own widgets in a straightforward manner.  The obvious benefit of facilitating the development by various third parties, is the associated growth in the PINV feature set. Additionally, we plan to continue the development of PINV widgets, and improve the existing ones.  For example, we are aiming to extend the circular layout to include multi-radial representations, which will allow us to represent hierarchies in a more intuitive way. This feature will also facilitate the further use of the spatial clustering information presented in this layout.

PINV reuses several BioJS components for the visualisation widgets, however, it currently uses BioJS 1.0 and should be updated to BioJS 2.0 in future. This will facilitate the inclusion of any new components that have been included in the new registry, some of which are working with PPI network data.

The proposed method to explore whole datasets using a spatial clustering algorithm does not offer a complete representation of the real network, and we are aware of several implications this may have, for example, that the partition by quadtrees can split well-defined clusters, which other methods can easily detect. However, we consider that the use of quadtrees provides a partial solution that is efficient and allows an easy way to explore a whole dataset from top to bottom.

We are eager to apply the knowledge acquired during this doctorate in other domains. PINVs architecture is reusable, and its modular design makes it an ideal framework to build applications for retrieving information from a centralised indexed systems; the inclusion of widgets and their execution order has been defined clearly in configuration files, which allows for easy customisation. Using PINV's architecture in a different domain won't only save time and resources on development, but will also facilitate the interaction between applications that share the same framework.

\vspace{5mm}

Science is not a solo campaign. Every researcher uses the current knowledge platform as a base for future projects and, at present, the best tool to access information is the web. Journals have made their articles available online, international consortiums provide their data in the same way, books and other learning resources are now a click away, and the communication between international peers can now be done with multiple methods including emails, video calls, and instant messaging, to name only a few.

A common factor throughout the projects that we have developed during this PhD, is the use of web technologies: MyDas facilitates sharing data using web protocols; DASty takes protein data from distributed sources and displays this information in a single web client view; probeSearcher, provides a web interface to find a microarray chip that covers proteins of interest; PINV uses the most modern web technologies in order to explore PPI data extensively. 

In conclusion, the web is not the future, is the present, and it is our goal as developers of scientific tools, to take advantage of the web's benefits to help researchers in their everyday tasks.

